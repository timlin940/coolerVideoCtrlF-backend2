import os
import psycopg2
from datetime import timedelta
from sentence_transformers import SentenceTransformer
#from app.chroma_client import ChromaDBClient
from chromadb import PersistentClient
from chromadb.config import Settings
import json
import google.generativeai as genai
import re


api_key =  os.getenv("GEMINI_API_KEY")

genai.configure(api_key=api_key)
# === å…±ç”¨å·¥å…· ===
def parse_time(ts):
    h, m, s = ts.split(":")
    return timedelta(hours=int(h), minutes=int(m), seconds=float(s))

def find_start_index(transcript_json, target_time):
    """å¾žå­—å¹•ä¸­æ‰¾åˆ°ç¬¬ä¸€å€‹é–‹å§‹æ™‚é–“ >= target_time çš„ index"""
    for i, seg in enumerate(transcript_json):
        if parse_time(seg["start"]) >= parse_time(target_time):
            return i
    return len(transcript_json)

def slice_transcript_block(transcript_json, start_index, max_tokens=2000):
    total_tokens = 0
    block = []
    for i in range(start_index, len(transcript_json)):
        text = transcript_json[i]["content"]
        approx_tokens = len(text) // 4
        if total_tokens + approx_tokens > max_tokens:
            break
        block.append(transcript_json[i])
        total_tokens += approx_tokens
    return block

def gemini_segment_and_summarize(subtitle_slices):
    text_block = ""
    for seg in subtitle_slices:
        text_block += f"[{seg['start']} - {seg['end']}] {seg['content']}\n"

    prompt = f"""
ä½ æ˜¯èªžæ„åˆ†æ®µåŠ©æ‰‹ï¼Œè«‹ä¾æ“šä¸‹æ–¹å­—å¹•ï¼ˆåŒ…å«æ™‚é–“èˆ‡å°æ‡‰æ–‡å­—ï¼‰é€²è¡Œåˆ‡æ®µæ‘˜è¦ï¼š
{text_block}

è«‹æ ¹æ“šèªžæ„åˆ‡åˆ†é€™äº›å­—å¹•æ®µè½ï¼Œæ¯æ®µéœ€è¦ï¼š
1. é–‹å§‹æ™‚é–“èˆ‡çµæŸæ™‚é–“ï¼ˆä¸èƒ½è¶…å‡ºæä¾›è³‡æ–™ï¼‰
2. æ¯æ®µæ‘˜è¦ï¼ˆ1ï½ž2 å¥**è‹±æ–‡**ï¼‰
3. æ¯30ç§’å·¦å³åˆ‡åˆ†ä¸€æ¬¡(å¿…é ˆå°æ–¼ç­‰æ–¼30ç§’)ï¼Œå¦‚æžœæœ‰é‡è¤‡çš„å…§å®¹å¯ä»¥åˆä½µæˆä¸€æ®µã€‚

è«‹å›žå‚³**ç´” JSON é™£åˆ—**ï¼Œä¸è¦åŠ ä¸Š```jsonæˆ–ä»»ä½•Markdownç¬¦è™Ÿã€‚
æ ¼å¼å¦‚ä¸‹ï¼š
[
  {{"start": "00:00:00", "end": "00:00:05", "summary": "æ®µè½æ‘˜è¦"}}
]
"""
    model_ai = genai.GenerativeModel('gemini-1.5-flash')
    response = model_ai.generate_content(prompt)
    raw_text = response.text if hasattr(response, "text") else response.parts[0].text
    print("ðŸ“¥ Gemini å›žå‚³åŽŸæ–‡ï¼š\n", raw_text)

    # ç”¨ regex æå–ç¬¬ä¸€å€‹åˆæ³•çš„ JSON é™£åˆ—
    json_match = re.search(r"\[\s*{.*?}\s*\]", raw_text, re.DOTALL)
    if not json_match:
        print("âŒ ç„¡æ³•å¾ž Gemini å›žå‚³ä¸­æå–åˆæ³• JSONã€‚")
        print(raw_text)
        return []

    try:
        return json.loads(json_match.group(0))
    except json.JSONDecodeError as e:
        print("âŒ JSON æ ¼å¼éŒ¯èª¤ï¼š", e)
        print("ðŸ‘‰ éŒ¯èª¤è¼¸å…¥ï¼š\n", json_match.group(0))
        return []

def process_subtitles_with_gemini(video_id, transcript_json, url, title, model_st, collection_chunk):
    current_time = transcript_json[0]["start"]

    while True:
        start_idx = find_start_index(transcript_json, current_time)
        if start_idx >= len(transcript_json):
            break

        block = slice_transcript_block(transcript_json, start_idx)
        if not block:
            break

        try:
            segments = gemini_segment_and_summarize(block)
            if not segments:
                break

            for i, seg in enumerate(segments):
                summary = seg["summary"].strip()
                chunk_id = f"{video_id}_gemini_{seg['start']}_{seg['end']}"
                
                if chunk_id in existing_ids_chunk:
                    continue  # å·²å­˜åœ¨å°±è·³éŽè©²æ®µ

                vector = model_st.encode([summary])[0].tolist()
                collection_chunk.add(
                    documents=[summary],
                    embeddings=[vector],
                    ids=[chunk_id],
                    metadatas=[{
                        "video_id": video_id,
                        "start": seg["start"],
                        "end": seg["end"],
                        "summary": summary,
                        "url": url,
                        "title": title
                    }]
                )
                print(f"âœ… å„²å­˜æ®µè½ï¼š{chunk_id}")

            # âœ… å„²å­˜å®Œæ‰€æœ‰æ®µè½å¾Œï¼Œå†æª¢æŸ¥æ™‚é–“æœ‰ç„¡å‰é€²
            next_time = segments[-1]["end"]
            if current_time == next_time:
                print(f"âš ï¸ åµæ¸¬åˆ°ç„¡æ™‚é–“å‰é€²ï¼Œè·³å‡ºå¾ªç’°ï¼š{current_time}")
                break
            current_time = next_time

        except Exception as e:
            print(f"âŒ Gemini åˆ†æžéŒ¯èª¤ï¼švideo_id={video_id}ï¼ŒéŒ¯èª¤ï¼š{e}")
            break

# === ChromaDB åˆå§‹åŒ– ===
# client = ChromaDBClient.get_instance().get_client() #åŽŸç‰ˆ
client = PersistentClient(path="test_chroma_db", settings=Settings(allow_reset=True))
collection_tt = client.get_or_create_collection(name="title_tag_emb")
collection_st = client.get_or_create_collection(name="summary_transcription_emb")
collection_chunk = client.get_or_create_collection(name="transcription_chunks_emb")

# === æ¨¡åž‹åˆå§‹åŒ– ===
model_tt = SentenceTransformer("paraphrase-MiniLM-L6-v2")
model_st = SentenceTransformer("BAAI/bge-m3")

# === PostgreSQL é€£ç·š ===
print("ðŸ” é€£ç·šåˆ° PostgreSQL ä¸­...")
#DATABASE_URL = os.getenv("DATABASE_URL") or "postgresql://postgres:pMHQKXAVRWXxhylnCiKOmslOKgVbjdvM@switchyard.proxy.rlwy.net:43353/railway"
DATABASE_URL = "postgresql://postgres:Functrol@localhost:5432/postgres"
conn = psycopg2.connect(DATABASE_URL)
cursor = conn.cursor()

# === æŠ“å½±ç‰‡åŸºæœ¬è³‡æ–™ + å­—å¹• ===
cursor.execute("""
    SELECT 
        v.id AS video_id,
        v.url,
        v.title,
        v.summary,
        v.transcription,
        v.transcription_with_time,
        -- èšåˆ tag åç¨±
        (
            SELECT STRING_AGG(t.name, '; ')
            FROM jsonb_array_elements_text(v.tag_ids) AS tag_id_text
            JOIN tags t ON t.id = tag_id_text::int
        ) AS tags
    FROM video_categories vc 
    JOIN videos v ON v.id = vc.video_id 
    JOIN categories c ON vc.category_id = c.id
    WHERE v.transcription_with_time IS NOT NULL AND v.id > 455 AND v.id < 461
    GROUP BY v.id, v.url, v.title, v.summary, v.transcription, v.transcription_with_time, v.tag_ids
    ORDER BY v.id
""")                                                # å¯ä»¥é€éŽå…©å€‹andé‚£è¡Œä¾†å°ˆé–€å­˜ç‰¹å®šç¯„åœçš„ç‰‡æ®µ
rows = cursor.fetchall()
columns = [desc[0] for desc in cursor.description]

# === å·²å­˜åœ¨çš„ IDï¼ˆé¿å…é‡è¤‡ï¼‰ ===
existing_ids_tt = set(collection_tt.get()["ids"])
existing_ids_st = set(collection_st.get()["ids"])
existing_ids_chunk = set(collection_chunk.get()["ids"])

# === æ¬„ä½å°æ‡‰æ¨¡åž‹èˆ‡ collection ===
field_mapping = {
    "title": (collection_tt, model_tt),
    "tags": (collection_tt, model_tt),
    "summary": (collection_st, model_st),
    "transcription": (collection_st, model_st),
}

for row in rows:
    row_dict = dict(zip(columns, row))
    video_id = str(row_dict["video_id"])
    url = row_dict["url"]
    title = row_dict["title"]
    t_with_time = row_dict["transcription_with_time"]

    # === å„²å­˜ title/tags/summary/transcription å‘é‡ ===
    for field, (collection, model) in field_mapping.items():
        content = (row_dict.get(field) or "").strip()
        if not content:
            continue

        uid = f"{video_id}_{field}"
        if (field in ["title", "tags"] and uid in existing_ids_tt) or \
           (field in ["summary", "transcription"] and uid in existing_ids_st):
            print(f"âš ï¸ å·²å­˜åœ¨ï¼š{uid}ï¼Œè·³éŽå„²å­˜")
            continue

        vector = model.encode([content])[0].tolist()
        collection.add(
            documents=[content],
            embeddings=[vector],
            ids=[uid],
            metadatas=[{
                "video_id": video_id,
                "field": field,
                "url": url,
                "title": title,
                "tags": row_dict["tags"]
            }]
        )
    # === è™•ç† Gemini å­—å¹•åˆ†æ®µæ‘˜è¦ï¼ˆåŠ åœ¨æ¯éƒ¨å½±ç‰‡è¿´åœˆå…§ï¼‰===
    try:
        process_subtitles_with_gemini(
            video_id=video_id,
            transcript_json=t_with_time,
            url=url,
            title=title,
            model_st=model_st,
            collection_chunk=collection_chunk
        )
    except Exception as e:
        print(f"âŒ è™•ç† Gemini åˆ†æ®µå¤±æ•—ï¼švideo_id={video_id}ï¼ŒéŒ¯èª¤ï¼š{e}")

cursor.close()
conn.close()
print("âœ… å·²æˆåŠŸå°‡æ‰€æœ‰å½±ç‰‡æ¬„ä½èˆ‡å­—å¹•ç‰‡æ®µå‘é‡å„²å­˜å®Œæˆï¼")