# åœ¨èƒŒæ™¯è‡ªå‹•ä¸‹è¼‰å½±ç‰‡
import subprocess
import json, re, os
import psycopg2
from datetime import datetime
import google.generativeai as genai
import time
import random
import requests
from dotenv import load_dotenv
from app.services.vectordb_search_for_main import get_latest_id,store_emb
# è‡ªå‹•ä¸‹è¼‰

load_dotenv()

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound

#æˆ‘æŠŠyt-dlp.exeæ”¾åœ¨backendè³‡æ–™å¤¾ä¸‹ï¼Œç”¨ä¾†æœå°‹YouTubeå½±ç‰‡

# âœ… å‘¼å«
api_key =  os.getenv("GEMINI_API_KEY")

genai.configure(api_key=api_key)

def time_str_to_str(time_str):
    parts = time_str.split(":")
    if len(parts) == 3:
        h = int(parts[0])
        m = int(parts[1])
        s = int(float(parts[2]))
        return f"{h}:{m:02}:{s:02}"
    elif len(parts) == 2:
        m = int(parts[0])
        s = int(float(parts[1]))
        return f"0:{m:02}:{s:02}"
    else:
        return "0:00:00"

def seconds_to_time_str(seconds):
    h = int(seconds // 3600)
    m = int((seconds % 3600) // 60)
    s = int(seconds % 60)
    return f"{h:02}:{m:02}:{s:02}"

def login_postgresql():
    print(" è«‹ç™»å…¥ PostgreSQL è³‡æ–™åº«")
    
    try:
        DATABASE_URL = (
            os.getenv("DATABASE_URL") or 
            "postgresql://postgres:pMHQKXAVRWXxhylnCiKOmslOKgVbjdvM@switchyard.proxy.rlwy.net:43353/railway"
        )
        conn = psycopg2.connect(DATABASE_URL)
        print(" æˆåŠŸé€£ç·šåˆ° PostgreSQLï¼")
        return conn
    except Exception as e:
        print(" é€£ç·šå¤±æ•—ï¼š", e)
        exit()

def search_youtube_with_subtitles(keyword, max_results=10):
    yt_dlp_path = r"C:\Users\user\Desktop\Functrol\backend\yt-dlp.exe"
    print(f"\U0001f50d æœå°‹é—œéµå­—ï¼š{keyword}")
    command = [
        yt_dlp_path,
        f"ytsearch{max_results}:{keyword}",
        "--dump-json",
        "--no-warnings"
    ]
    try:
        result = subprocess.run(command, capture_output=True, text=True, check=True)
        lines = result.stdout.strip().split('\n')
        valid_videos = []
        for line in lines:
            video_data = json.loads(line)
            if video_data.get("subtitles") or video_data.get("automatic_captions"):
                valid_videos.append({
                    "title": video_data.get("title"),
                    "url": video_data.get("webpage_url"),
                    "description": video_data.get("description"),
                    "duration": video_data.get("duration_string"),
                    "channel": video_data.get("channel")
                })
        return valid_videos
    except subprocess.CalledProcessError as e:
        print(" åŸ·è¡Œ yt-dlp ç™¼ç”ŸéŒ¯èª¤ï¼š", e)
        return []
    
def generate_summary_with_gemini(text, prompt="è«‹ç‚ºä»¥ä¸‹å½±ç‰‡å­—å¹•ç”Ÿæˆä¸€æ®µç²¾ç°¡çš„è‹±æ–‡æ‘˜è¦(é¿å…é€å¥ç¿»è­¯)ï¼š"):
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        response = model.generate_content(prompt + text)
        return response.text.strip()
    except Exception as e:
        print("âŒ Gemini æ‘˜è¦å¤±æ•—ï¼š", e)
        return False
    
def predict_topic_with_gemini(summary_text):
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        prompt = (
            f"é€™æ˜¯ä¸€æ®µYouTubeå½±ç‰‡çš„æ‘˜è¦å…§å®¹ï¼š{summary_text}\n"
            "è«‹æ ¹æ“šä»¥ä¸‹ä¸»é¡Œåˆ†é¡ä¸­ï¼Œé¸å‡ºæœ€é©åˆçš„2å€‹ä¸»é¡Œï¼ˆåªå›å‚³è‹±æ–‡ä¸»é¡Œåç¨±ï¼Œç”¨é€—è™Ÿåˆ†éš”ï¼‰ï¼š\n"
            "Computer Science, Law, Mathematics, Physics, Chemistry, Biology, Earth Science, History, Geography, Sports, Astronomy, Daily Lifeã€‚\n"
            "è«‹å‹¿è‡ªè¡Œå‰µé€ å…¶ä»–åˆ†é¡ã€‚"
        )
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        print("âŒ Gemini ä¸»é¡Œåˆ†é¡å¤±æ•—ï¼š", e)
        return "Daily Life"  # fallback é è¨­å€¼

def get_or_create_tags(summary, conn):
    try:
        cursor = conn.cursor()
        cursor.execute("SELECT id, name FROM tags")
        tag_rows = cursor.fetchall()
        tag_dict = {t.lower(): i for i, t in tag_rows}
        tag_list = list(tag_dict.keys())

        prompt = f"""
    ä½ æ˜¯å°ˆæ¥­çš„çŸ¥è­˜åˆ†é¡å°ˆå®¶ï¼Œè«‹æ ¹æ“šä¸‹åˆ—å½±ç‰‡æ‘˜è¦ï¼Œåš´æ ¼éµå®ˆè¦å‰‡é¸å‡ºæœ€é©åˆçš„ 3 å€‹è‹±æ–‡æ¨™ç±¤ï¼ˆç”¨é€—è™Ÿåˆ†éš”ï¼Œä¸å¾—å¤šæ–¼ 3 å€‹ï¼‰ï¼š

    æ‘˜è¦å…§å®¹å¦‚ä¸‹ï¼š
    ã€Œ{summary}ã€

    å·²çŸ¥æ¨™ç±¤æ¸…å–®å¦‚ä¸‹ï¼š
    {', '.join(tag_list)}

    è«‹**å‹™å¿…éµå®ˆä»¥ä¸‹è¦å‰‡**ï¼š

    1. å„ªå…ˆå¾æ¸…å–®ä¸­æŒ‘é¸ 3 å€‹æœ€è²¼è¿‘æ‘˜è¦ä¸»é¡Œçš„æ¨™ç±¤ã€‚
    2. è‹¥æ¸…å–®ä¸­æ²’æœ‰åˆé©çš„ï¼Œè«‹**ç›´æ¥å‰µé€ æ–°çš„æ¨™ç±¤ï¼ˆæœ€å¤š 3 å€‹ï¼‰**ã€‚
    3. **ç¦æ­¢å‰µé€ èˆ‡ç¾æœ‰æ¨™ç±¤èªæ„é‡è¤‡æˆ–ç›¸è¿‘çš„æ¨™ç±¤**ï¼ˆä¾‹å¦‚å·²æœ‰ Machine Learningï¼Œå°±ä¸èƒ½å‰µé€  ML æˆ– AI MLï¼‰ã€‚
    4. æ–°æ¨™ç±¤å¿…é ˆæ˜¯**æ¸…æ¥šã€ç°¡çŸ­ã€æ„ç¾©æ˜ç¢ºçš„è‹±æ–‡è©å½™**ï¼Œä¸”**é™åˆ¶ç‚ºå…©å€‹å–®å­—ä»¥å…§**ã€‚
    5. åƒ…å›å‚³æ¨™ç±¤å…§å®¹ï¼Œç”¨è‹±æ–‡é€—è™Ÿåˆ†éš”ï¼Œ**ä¸è¦é™„åŠ ä»»ä½•æ–‡å­—ã€å¼•è™Ÿã€æ ¼å¼ç¬¦è™Ÿæˆ–èªªæ˜**ã€‚

    ç¯„ä¾‹æ­£ç¢ºå›è¦†æ ¼å¼ï¼ˆåƒ…ä¾›åƒè€ƒï¼‰ï¼š
    AI, Blockchain, Cybersecurity
    """
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        response = model.generate_content(prompt)
        tags_raw = response.text.strip()
        tags = [t.strip() for t in tags_raw.split(",") if t.strip()]

        tag_ids = []
        for tag in tags:
            tag_lower = tag.lower()
            if tag_lower in tag_dict:
                tag_ids.append(tag_dict[tag_lower])
            else:
                cursor.execute("INSERT INTO tags (name) VALUES (%s) RETURNING id", (tag,))
                new_id = cursor.fetchone()[0]
                tag_ids.append(new_id)
                conn.commit()

        return tag_ids

    except Exception as e:
        print("âŒ ç”¢ç”Ÿæ¨™ç±¤å¤±æ•—ï¼š", e)
        return []

def generate_highlights_text_with_gemini(subtitles) :
    prompt = f"""
        ä½ æ˜¯æ•™å­¸åŠ©æ•™ã€‚è«‹é–±è®€ä»¥ä¸‹é€æ®µå­—å¹•å…§å®¹ï¼Œèƒå–æœ€é‡è¦çš„5å€‹é‡é»ï¼Œã€‚
        **è¼¸å‡ºè¦å‰‡**ï¼š
        - ç”¨ç¹é«”ä¸­æ–‡ï¼Œå¯ä»¥ä¿ç•™è‹±æ–‡å°ˆæœ‰åè©
        - æ¯å€‹é‡é» â‰¤ 40 å­—
        - é‡é»è¦æ¸…æ¥šã€æ˜ç¢º
        - æ¯å€‹é‡é»ç¨ç«‹ä¸€è¡Œï¼Œä¸”**ä»¥æ•¸å­—ä½œç‚ºé–‹é ­**
        - **ä¸è¦**è¼¸å‡ºä»»ä½•æ¨™é¡Œã€èªªæ˜ã€JSONã€ç¨‹å¼ç¢¼æ¡†æˆ–å¤šé¤˜æ–‡å­—
        - ç¯„æœ¬ï¼Œ**é‡é»ä¹‹é–“ä¸éœ€è¦ç©ºä¸€è¡Œ**ï¼š
        - **1.é€™æ˜¯ç¬¬ä¸€å€‹é‡é»**
        - **2.é€™æ˜¯ç¬¬äºŒå€‹é‡é»**

        å­—å¹•ï¼š
        {subtitles}
        """
    try:
        model = genai.GenerativeModel("gemini-2.5-flash-lite")
        resp = model.generate_content(prompt)
        resp = resp.text.strip()
        return resp
    except Exception as e:
        print("âŒ Gemini ç”¢ç”Ÿé‡é»å¤±æ•—ï¼š", e)
        return ""

def is_embeddable(video_url: str, timeout=5) -> bool:
    """
    æª¢æŸ¥ YouTube å½±ç‰‡æ˜¯å¦å…è¨±åµŒå…¥ (oEmbed API)
    å¦‚æœä¸èƒ½åµŒå…¥ï¼Œä»£è¡¨å½±ç‰‡å¯èƒ½æ˜¯ç§æœ‰ã€éœ€è¦ç™»å…¥ã€åœ°å€é™åˆ¶æˆ–è¢«ä¸‹æ¶ã€‚
    """
    try:
        r = requests.get(
            "https://www.youtube.com/oembed",
            params={"url": video_url, "format": "json"},
            timeout=timeout,
        )
        return r.status_code == 200
    except requests.RequestException:
        return False

def download_and_save_to_postgresql(video_url, title, description, conn, language="en"):
    print(f"\U0001f3ac è™•ç†å½±ç‰‡ï¼š{video_url}")
    # âœ… åµŒå…¥æª¢æŸ¥ï¼šé¿å…å­˜åˆ°ä¸å¯è§€çœ‹çš„å½±ç‰‡
    if not is_embeddable(video_url):
        print(f"âŒ æ­¤å½±ç‰‡ç„¡æ³•åµŒå…¥æˆ–ä¸å¯è§€çœ‹ï¼Œç•¥éï¼š{video_url}")
        return
    video_id = video_url.split("v=")[-1]

    cursor = conn.cursor()
    cursor.execute("SELECT id FROM videos WHERE url = %s", (video_url,))
    if cursor.fetchone():
        print(f" å½±ç‰‡å·²å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­ï¼Œç•¥éï¼š{video_url}")
        return
    try:
        try:
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            try:
                # å„ªå…ˆä½¿ç”¨æ‰‹å‹•å­—å¹•
                transcript = transcript_list.find_manually_created_transcript([language]).fetch()
            except NoTranscriptFound:
                # è‹¥æ²’æœ‰æ‰‹å‹•å­—å¹•ï¼Œå†æ‰¾è‡ªå‹•å­—å¹•
                transcript = transcript_list.find_generated_transcript([language]).fetch()
        except (TranscriptsDisabled, NoTranscriptFound):
            print(f"âŒ æ­¤å½±ç‰‡ç„¡ {language} å­—å¹•ï¼š{video_url}")
            return
        structured_subtitles = []
        output_lines = []

        for i, entry in enumerate(transcript):
            start = entry.start
            duration = entry.duration
            content = entry.text.strip()

            # æ ¼å¼åŒ–ç‚º mm:ss
            mmss = time_str_to_str(seconds_to_time_str(start))

            # ç§»é™¤ HTML æ¨™ç±¤èˆ‡é›œè¨Š
            content = re.sub(r"<.*?>", "", content)
            content = re.sub(r"\[.*?\]", "", content)
            content = re.sub(r"\s+", " ", content)

            # å¿½ç•¥ç©ºæ®µè½
            if not content:
                continue

            # éæ¿¾é‡è¤‡
            if structured_subtitles and content in structured_subtitles[-1]["content"]:
                continue

            start_sec = start
            end_sec = start + duration

            structured_subtitles.append({
                "start": time_str_to_str(seconds_to_time_str(start_sec)),
                "end": time_str_to_str(seconds_to_time_str(end_sec)),
                "content": content
            })
            output_lines.append(content)

        subtitle_text = "\n".join(output_lines)

        # å„²å­˜å½±ç‰‡é•·åº¦ï¼ˆå–æœ€å¾Œå­—å¹•çµæŸæ™‚é–“ï¼‰
        if transcript:
            last_end = transcript[-1].start + transcript[-1].duration
            duration_str = time_str_to_str(seconds_to_time_str(last_end))
            duration_sec = int(last_end)
            if duration_sec < 180:
                print(f" å½±ç‰‡é•·åº¦åƒ… {duration_str}ï¼Œå°‘æ–¼ 3 åˆ†é˜ï¼Œç•¥éå„²å­˜")
                return
            if duration_sec > 7200:
                print(f" å½±ç‰‡é•·åº¦ {duration_str}ï¼Œå¤§æ–¼ 2 å°æ™‚ï¼Œç•¥éå„²å­˜")
                return
        else:
            duration_str = ""

        # æ¸…ç†å­—å¹•å…§å®¹
        subtitle_text = clean_text(subtitle_text)

        # æŠ½å‡ºå…§åµŒç¶²å€
        embed_url = f"https://www.youtube.com/embed/{video_id}"

        # åš summary + ä¸»é¡Œåˆ†é¡
        summary = generate_summary_with_gemini(subtitle_text)
        assigned_categories = predict_topic_with_gemini(summary)

        # å–å¾—æˆ–å‰µå»ºæ¨™ç±¤
        tag_ids = get_or_create_tags(summary, conn) 
        # ç”Ÿæˆé‡é»helights
        highlights = generate_highlights_text_with_gemini(subtitle_text)


        assigned_categories = [t.strip() for t in assigned_categories.split(",")]
        if summary is False:
            print(f"âŒ æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼Œç•¥éå„²å­˜ï¼š{video_url}")
            return
        # å„²å­˜åˆ°è³‡æ–™åº«
        cursor.execute("""
            INSERT INTO videos (url, title, description, summary, transcription, transcription_with_time, duration_str, embed_url, created_at,tag_ids, highlights)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s,%s,%s)
            RETURNING id;
        """, (
            video_url, title, description, summary, subtitle_text,
            json.dumps(structured_subtitles, ensure_ascii=False),
            duration_str, embed_url, datetime.utcnow(),json.dumps(tag_ids), highlights
        ))

        new_video_id = cursor.fetchone()[0]
        for topic in assigned_categories:
            cursor.execute("SELECT id FROM categories WHERE topic = %s", (topic,))
            result = cursor.fetchone()
            if result:
                category_id = result[0]
                cursor.execute("INSERT INTO video_categories (video_id, category_id) VALUES (%s, %s)", (new_video_id, category_id))
            else:
                print(f"âš ï¸ æ‰¾ä¸åˆ°åˆ†é¡ï¼š{topic}ï¼Œç•¥éæ­¤åˆ†é¡")

        conn.commit()
        print(f"âœ… æˆåŠŸå„²å­˜å½±ç‰‡ï¼š{title}ï¼Œä¸»é¡Œï¼š{', '.join(assigned_categories)}")

    except Exception as e:
        print("âŒ ç™¼ç”ŸéŒ¯èª¤ï¼š", e)

def clean_text(text):#æ¸…ç†å­—å¹•æª”
    text = re.sub(r'WEBVTT.*?\n', '', text, flags=re.DOTALL)
    text = re.sub(r'\[[^\]]+\]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()

    return text

#  ä¸»ç¨‹å¼ï¼šè‡ªå‹•ä¸‹è¼‰å½±ç‰‡ä¸¦å­˜åˆ°è³‡æ–™åº«ï¼Œé‚„éœ€è¦store_all_embd
def auto_download(keywords):
    conn = login_postgresql()
    for keyword in keywords:
        videos = search_youtube_with_subtitles(keyword, max_results=2)
        print(f"ğŸ” æ‰¾åˆ° {len(videos)} æ”¯æœ‰å­—å¹•çš„å½±ç‰‡")
        for video in videos:
            download_and_save_to_postgresql(video["url"], video["title"], video["description"], conn, language="en")
            time.sleep(20 + random.randint(0, 5))
        # ç”¨local_view_collectionæ‰¾ç¾åœ¨æœ€æ–°çš„collectionåˆ°å“ªè£¡
        #########################################################################################(ä»¥ä¸Šä¸‹è¼‰å½±ç‰‡åˆ°SQLæ²’å•é¡Œ)
        latest_id = get_latest_id()#å‡ºç¾vocabå•é¡Œ
        # ç”¨store_all_embdå„²å­˜å‘é‡
        print("æœ€æ–°çš„è³‡æ–™åº«:",latest_id)
        store_emb(latest_id, conn)
    print("å½±ç‰‡ä¸‹è¼‰ä¸¦è™•ç†å®Œæˆ")
    conn.close()